{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import io\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import gzip\n",
    "import torch\n",
    "import spacy\n",
    "import string\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import mwparserfromhell\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peeyush/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# set file names for dumping pickle files and input data source\n",
    "FILE_NAME = 'data/sample_1pct_wikitext.json'\n",
    "\n",
    "PRETRAINED_EMBEDDINGS = 'pretrained-embeddings/wiki-news-300d-1M.vec'\n",
    "\n",
    "OUTPUT_FILE = 'tokenized-data/wikitext_tokenized.p'\n",
    "#OUTPUT_FILE_2 = 'tokenized-data/wikitext_tokenized_reduced.p'\n",
    "\n",
    "WIKI_TRAIN_TOKENIZED_FILE = 'tokenized-data/wiki_train_tokenized.p'\n",
    "WIKI_VALID_TOKENIZED_FILE = 'tokenized-data/wiki_valid_tokenized.p'\n",
    "WIKI_TEST_TOKENIZED_FILE  = 'tokenized-data/wiki_test_tokenized.p'\n",
    "\n",
    "MAX_ARTICLE_LENGTH = 500\n",
    "\n",
    "# downloading and setting stop word list from NLTK\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "    tokens = tokenizer(sent)\n",
    "    return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "# clean text using regex - similar to what is used in FastText paper\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    patterns = [\n",
    "        \"{{.*}}\"\n",
    "        ,\"&amp;\"\n",
    "        ,\"&lt;\"\n",
    "        ,\"&gt;\"\n",
    "        ,\"<ref[^<]*<\\/ref>\"\n",
    "        ,\"<[^>]*>\"\n",
    "        ,\"\\|left\"\n",
    "        ,\"\\|\\d+px\"\n",
    "        ,\"\\[\\[category:\"\n",
    "        ,r\"(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b\"\n",
    "        ,\"\\|thumb\"\n",
    "        ,\"\\|right\"\n",
    "        ,\"\\[\\[image:[^\\[\\]]*\"\n",
    "        ,\"\\[\\[category:([^|\\]]*)[^]]*\\]\\]\"\n",
    "        ,\"\\[\\[[a-z\\-]*:[^\\]]*\\]\\]\"\n",
    "        ,\"\\[\"\n",
    "        ,\"\\]\"\n",
    "        ,\"\\{[^\\}]*\\}\"\n",
    "        ,r\"\\n\"\n",
    "        ,r\"[^a-zA-Z0-9 ]\"\n",
    "        ,r\"\\b[a-zA-Z]\\b\"\n",
    "        ,\" +\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        cleanr = re.compile(pattern)\n",
    "        text = re.sub(cleanr, ' ', text)\n",
    "    return text\n",
    "\n",
    "# covert numerals to their text equivalent\n",
    "def subsitute(text):\n",
    "    return text.strip().replace('0', ' zero') \\\n",
    "                        .replace('1',' one') \\\n",
    "                        .replace('2',' two') \\\n",
    "                        .replace('3',' three') \\\n",
    "                        .replace('4',' four') \\\n",
    "                        .replace('5',' five') \\\n",
    "                        .replace('6',' six') \\\n",
    "                        .replace('7',' seven') \\\n",
    "                        .replace('8',' eight') \\\n",
    "                        .replace('9',' nine')\n",
    "\n",
    "# remove empty token generated from inserting blank spaces\n",
    "def remove_empty_token(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if not token.strip() == '':\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "# optional - remove other common stop words \n",
    "# get the stop words from NLTK package\n",
    "def remove_stop_words(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if not token in STOP_WORDS:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "# optional - remove words less than 3 character long\n",
    "def remove_short_words(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if len(token) >= 3:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "# get the tokenized dataframe containing - QID, Word Tokens & Categories\n",
    "def get_wiki_tokenized_dataset(file_name):\n",
    "    wiki_dict = []\n",
    "    with open(FILE_NAME) as file:\n",
    "         for line in file:\n",
    "            wiki_row = {}\n",
    "            line = json.loads(line.strip())\n",
    "            wikitext = mwparserfromhell.parse(line['wikitext'])\n",
    "            wiki_row['QID'] = line['QID']\n",
    "            wiki_row['mid_level_categories'] = line['mid_level_categories']\n",
    "            wiki_row['tokens'] = tokenize(subsitute(clean(str(wikitext))))\n",
    "            wiki_dict.append(wiki_row)\n",
    "\n",
    "    wiki_df = pd.DataFrame(wiki_dict)\n",
    "    wiki_df['tokens'] = wiki_df['tokens'].apply(remove_empty_token)\n",
    "    return wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the dataset in pickle file for subsequent use\n",
    "# # Download the pickle files from Google Drive (else creating new will take ~4 hours)\n",
    "# # https://drive.google.com/open?id=1DlNxxNh6WA5ds7px844LnBbhEzV0Ydyo\n",
    "# wiki_df = get_wiki_tokenized_dataset(FILE_NAME)\n",
    "# pkl.dump(wiki_df, open(OUTPUT_FILE, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe from pickle file\n",
    "wiki_df =  pkl.load(open(OUTPUT_FILE, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df['tokens'] = wiki_df['tokens'].apply(remove_short_words)\n",
    "wiki_df['tokens'] = wiki_df['tokens'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([word for article in wiki_df.tokens for word in article])\n",
    "token_df = a.value_counts().sort_index().rename_axis('word').reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aaa</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aaaaa</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>aaaayaaj</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>aaai</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694607</td>\n",
       "      <td>zytek</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694623</td>\n",
       "      <td>zyx</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694625</td>\n",
       "      <td>zyxin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694629</td>\n",
       "      <td>zyzzyva</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694646</td>\n",
       "      <td>zzyzx</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156408 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count\n",
       "0            aaa    561\n",
       "1           aaaa     41\n",
       "2          aaaaa      9\n",
       "15      aaaayaaj      6\n",
       "22          aaai     10\n",
       "...          ...    ...\n",
       "694607     zytek      7\n",
       "694623       zyx     15\n",
       "694625     zyxin      8\n",
       "694629   zyzzyva      7\n",
       "694646     zzyzx     15\n",
       "\n",
       "[156408 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_freq_df = token_df[token_df['count'] > 5]\n",
    "tokens_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = wiki_df['tokens'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = b.value_counts().sort_index().rename_axis('count').reset_index(name='frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x16c57ef98>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_df.hist(column='count',bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIONAL - Remove in-frequent tokens from corpus (words repeated less than 100 times) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "infrequent_tokens_df = token_df[token_df['count'] <= 5]\n",
    "infrequent_tokens = infrequent_tokens_df['word'].tolist()\n",
    "infrequent_tokens = set(infrequent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove infrequent tokens\n",
    "def remove_infrequent_words(tokens):\n",
    "    result = [token for token in tokens if token not in infrequent_tokens]\n",
    "    return result\n",
    "\n",
    "wiki_df['tokens'] = wiki_df['tokens'].apply(remove_infrequent_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into Train, Valid & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_train, wiki_valid, wiki_test = train_validate_test_split(wiki_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained FASTText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained fastText embeddings\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(list(map(float, tokens[1:]))).astype('float32')\n",
    "    return data\n",
    "\n",
    "# # Download from - https://drive.google.com/open?id=1vfoiWQkEjyNXRyi0JzA8Aq5Zzjfcpo2w\n",
    "pretrained_embs = load_vectors(PRETRAINED_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique tokens in the training dataset\n",
    "all_train_tokens = []\n",
    "\n",
    "for tokens in wiki_train['tokens']:\n",
    "    for token in tokens:\n",
    "        all_train_tokens.append(token)\n",
    "        \n",
    "all_train_tokens = list(set(all_train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse the wiki tokens and fastText embeddings\n",
    "train_token_count = len(all_train_tokens)\n",
    "token_in_fasttext = []\n",
    "token_not_in_fasttext = []\n",
    "train_token_in_fasttxt = 0\n",
    "\n",
    "for token in all_train_tokens:\n",
    "    if token in pretrained_embs.keys():\n",
    "        token_in_fasttext.append(token)\n",
    "        train_token_in_fasttxt = train_token_in_fasttxt + 1\n",
    "    else:\n",
    "        token_not_in_fasttext.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of unique Wiki tokens in fASTText : 51.16%\n",
      "unique tokens not in fastText : 74980\n",
      "unique tokens in fastText : 78535\n"
     ]
    }
   ],
   "source": [
    "print(\"% of unique Wiki tokens in fASTText : {:4.2f}%\".format(train_token_in_fasttxt/train_token_count*100))\n",
    "print('unique tokens not in fastText :', len(token_not_in_fasttext))\n",
    "print('unique tokens in fastText :', len(token_in_fasttext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens not in the fastText\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['avele',\n",
       " 'radwan',\n",
       " 'bagar',\n",
       " 'iyashinai',\n",
       " 'salviati',\n",
       " 'sealdah',\n",
       " 'pubnub',\n",
       " 'shishmakov',\n",
       " 'chamonix',\n",
       " 'myrmicinae']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample tokens not in the fastText\")\n",
    "token_not_in_fasttext[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running test to investigate which words are not in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_dict = []\n",
    "article_percentage = []\n",
    "for idx, tokens in enumerate(wiki_train['tokens']):\n",
    "    count = 0\n",
    "    tokens_not_in_fasttext = []\n",
    "    fasttext_row = {}\n",
    "    for token in tokens:\n",
    "        if token in pretrained_embs.keys():\n",
    "            count = count + 1\n",
    "        else :\n",
    "            tokens_not_in_fasttext.append(token)\n",
    "    \n",
    "    if len(tokens) > 0:\n",
    "        percent = count/len(tokens) * 100\n",
    "    else:\n",
    "        percent = 100\n",
    "    \n",
    "    article_percentage.append(percent)\n",
    "    \n",
    "    if percent < 75:\n",
    "        fasttext_row['QID'] = wiki_train.iloc[idx]['QID'] \n",
    "        fasttext_row['Coverage'] = percent \n",
    "        fasttext_row['Tokens not in fastText'] = tokens_not_in_fasttext\n",
    "        fasttext_row['Total Tokens'] = len(tokens)\n",
    "        fasttext_dict.append(fasttext_row)\n",
    "        \n",
    "fasttext_df = pd.DataFrame(fasttext_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Tokens not in fastText</th>\n",
       "      <th>Total Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1251</td>\n",
       "      <td>Q15947284</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>[darreh, bizhan, darreh, bizhan, olya, darreh,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>Q6698784</td>\n",
       "      <td>17.647059</td>\n",
       "      <td>[ludia, ludia, capuron, sleumer, sleumer, ludi...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>Q4464501</td>\n",
       "      <td>21.777778</td>\n",
       "      <td>[saprinus, histeridae, saprinus, saprinus, sap...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>Q2367080</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>[amblyptilia, pterophoridae, amblyptilia, ambl...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q7607829</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>[stenoptilodes, pterophoridae, stenoptilodes, ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>Q278582</td>\n",
       "      <td>74.782609</td>\n",
       "      <td>[tyrol, tirol, tyrol, tyrol, tyrol, tyrol, tyr...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>Q2957616</td>\n",
       "      <td>74.789916</td>\n",
       "      <td>[nymphalidae, cajetan, felder, felder, indomal...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>Q39091117</td>\n",
       "      <td>74.806202</td>\n",
       "      <td>[actinocrinites, actinocrinites, actinocrinite...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>Q14662980</td>\n",
       "      <td>74.809160</td>\n",
       "      <td>[eutreta, tephritidae, eutreta, eutreta, eutre...</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065</td>\n",
       "      <td>Q20647492</td>\n",
       "      <td>74.869110</td>\n",
       "      <td>[hapoel, hapoel, hapoel, ironi, kiryat, shmona...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1467 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            QID   Coverage                             Tokens not in fastText  \\\n",
       "1251  Q15947284  15.384615  [darreh, bizhan, darreh, bizhan, olya, darreh,...   \n",
       "1428   Q6698784  17.647059  [ludia, ludia, capuron, sleumer, sleumer, ludi...   \n",
       "195    Q4464501  21.777778  [saprinus, histeridae, saprinus, saprinus, sap...   \n",
       "1284   Q2367080  22.222222  [amblyptilia, pterophoridae, amblyptilia, ambl...   \n",
       "0      Q7607829  25.000000  [stenoptilodes, pterophoridae, stenoptilodes, ...   \n",
       "...         ...        ...                                                ...   \n",
       "1110    Q278582  74.782609  [tyrol, tirol, tyrol, tyrol, tyrol, tyrol, tyr...   \n",
       "422    Q2957616  74.789916  [nymphalidae, cajetan, felder, felder, indomal...   \n",
       "559   Q39091117  74.806202  [actinocrinites, actinocrinites, actinocrinite...   \n",
       "131   Q14662980  74.809160  [eutreta, tephritidae, eutreta, eutreta, eutre...   \n",
       "1065  Q20647492  74.869110  [hapoel, hapoel, hapoel, ironi, kiryat, shmona...   \n",
       "\n",
       "      Total Tokens  \n",
       "1251            13  \n",
       "1428            68  \n",
       "195            225  \n",
       "1284            45  \n",
       "0               36  \n",
       "...            ...  \n",
       "1110           115  \n",
       "422            119  \n",
       "559            258  \n",
       "131            262  \n",
       "1065           191  \n",
       "\n",
       "[1467 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_df = fasttext_df.sort_values(by=['Coverage','Total Tokens'])\n",
    "fasttext_df\n",
    "#fasttext_df.to_csv('fastText-analysis.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average % of tokens coverage across articles in fastText : 94.34358723875535\n"
     ]
    }
   ],
   "source": [
    "print(\"Average % of tokens coverage across articles in fastText :\", sum(article_percentage)/len(wiki_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_NAME) as file:\n",
    "    for line in file:\n",
    "        line = json.loads(line.strip())\n",
    "        if line['QID'] == 'Q4464501':\n",
    "            wiki_text = mwparserfromhell.parse(line['wikitext'])\n",
    "            cleaned_text = subsitute(clean(str(wiki_text)))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{{Taxobox\\n| name = ''Saprinus''\\n| image = Histeridae - Saprinus ornatus.JPG\\n| image_width = 250px\\n| image_caption = ''[[Saprinus ornatus]]''\\n| regnum = [[Animal]]ia\\n| phylum = [[Arthropod]]a\\n| classis = [[Insect]]a\\n| ordo = [[Beetle|Coleoptera]]\\n| superfamilia = [[Histeroidea]]\\n| familia = [[Histeridae]]\\n| subfamilia = [[Histerinae]]\\n| genus = '''''Saprinus'''''\\n| genus_authority =Erichson, 1834\\n| synonyms =\\n}}\\n\\n'''''Saprinus''''' is a genus of clown beetles belonging to the family [[Histeridae]].\\n\\n==Species==\\n{{div col|colwidth=16em}}\\n* ''[[Saprinus aberlenci]]''\\n* ''[[Saprinus acuminatus]]''\\n* ''[[Saprinus addendus]]''\\n* ''[[Saprinus aegialius]]''\\n* ''[[Saprinus aegyptiacus]]''\\n* ''[[Saprinus aeneolus]]''\\n* ''[[Saprinus aeneus]]''\\n* ''[[Saprinus aequalis]]''\\n* ''[[Saprinus aeratus]]''\\n* ''[[Saprinus africanus]]''\\n* ''[[Saprinus algericus]]''\\n* ''[[Saprinus alienus]]''\\n* ''[[Saprinus amethystinus]]''\\n* ''[[Saprinus apteli]]''\\n* ''[[Saprinus artensis]]''\\n* ''[[Saprinus austerus]]''\\n* ''[[Saprinus australis]]''\\n* ''[[Saprinus basalis]]''\\n* ''[[Saprinus beduinus]]''\\n* ''[[Saprinus bicolor]]''\\n* ''[[Saprinus bicoloroides]]''\\n* ''[[Saprinus biguttatus]]''\\n* ''[[Saprinus bimaculatus]]''\\n* ''[[Saprinus biplagiatus]]''\\n* ''[[Saprinus blissonii]]''\\n* ''[[Saprinus bousaadensis]]''\\n* ''[[Saprinus brenskei]]''\\n* ''[[Saprinus brunnivestis]]''\\n* ''[[Saprinus buqueti]]''\\n* ''[[Saprinus caeruleatus]]''\\n* ''[[Saprinus caerulescens]]''\\n* ''[[Saprinus calatravensis]]''\\n* ''[[Saprinus cariniceps]]''\\n* ''[[Saprinus cavalieri]]''\\n* ''[[Saprinus centralis]]''\\n* ''[[Saprinus chalcites]]''\\n* ''[[Saprinus concinnus]]''\\n* ''[[Saprinus confalonierii]]''\\n* ''[[Saprinus cribellatus]]''\\n* ''[[Saprinus cruciatus]]''\\n* ''[[Saprinus crypticus]]''\\n* ''[[Saprinus cupratus]]''\\n* ''[[Saprinus cupreus]]''\\n* ''[[Saprinus cyaneus]]''\\n* ''[[Saprinus cyprius]]''\\n* ''[[Saprinus dahlgreni]]''\\n* ''[[Saprinus degallieri]]''\\n* ''[[Saprinus delta]]''\\n* ''[[Saprinus detersus]]''\\n* ''[[Saprinus detritus]]''\\n* ''[[Saprinus discoidalis]]''\\n* ''[[Saprinus distinguendus]]''\\n* ''[[Saprinus divergens]]''\\n* ''[[Saprinus diversegenitalis]]''\\n* ''[[Saprinus dussaulti]]''\\n* ''[[Saprinus erichsonii]]''\\n* ''[[Saprinus exiguus]]''\\n* ''[[Saprinus externus]]''\\n* ''[[Saprinus fallaciosus]]''\\n* ''[[Saprinus felipae]]''\\n* ''[[Saprinus figuratus]]''\\n* ''[[Saprinus flexuosofasciatus]]''\\n* ''[[Saprinus fraterculus]]''\\n* ''[[Saprinus fraudulentus]]''\\n* ''[[Saprinus frontistrius]]''\\n* ''[[Saprinus fulgidicollis]]''\\n* ''[[Saprinus funebris]]''\\n* ''[[Saprinus furvus]]''\\n* ''[[Saprinus gageti]]''\\n* ''[[Saprinus gambiensis]]''\\n* ''[[Saprinus georgicus]]''\\n* ''[[Saprinus gilvicornis]]''\\n* ''[[Saprinus godet]]''\\n* ''[[Saprinus goergeni]]''\\n* ''[[Saprinus graculus]]''\\n* ''[[Saprinus grandiclava]]''\\n* ''[[Saprinus guyanensis]]''\\n* ''[[Saprinus havajirii]]''\\n* ''[[Saprinus himalajicus]]''\\n* ''[[Saprinus immundus]]''\\n* ''[[Saprinus imperfectus]]''\\n* ''[[Saprinus impressus]]''\\n* ''[[Saprinus inausus]]''\\n* ''[[Saprinus infimus]]''\\n* ''[[Saprinus inflatus]]''\\n* ''[[Saprinus intractabilis]]''\\n* ''[[Saprinus intricatus]]''\\n* ''[[Saprinus jacobsoni]]''\\n* ''[[Saprinus kaszabianus]]''\\n* ''[[Saprinus lateralis]]''\\n* ''[[Saprinus lautus]]''\\n* ''[[Saprinus lindrothi]]''\\n* ''[[Saprinus lopatini]]''\\n* ''[[Saprinus lucemseductus]]''\\n* ''[[Saprinus lugens]]''\\n* ''[[Saprinus lutshniki]]''\\n* ''[[Saprinus maculatus]]''\\n* ''[[Saprinus magnoguttatus]]''\\n* ''[[Saprinus mastersii]]''\\n* ''[[Saprinus melas]]''\\n* ''[[Saprinus moyses]]''\\n* ''[[Saprinus muelleri]]''\\n* ''[[Saprinus multistriatus]]''\\n* ''[[Saprinus namibiensis]]''\\n* ''[[Saprinus niger]]''\\n* ''[[Saprinus niponicus]]''\\n* ''[[Saprinus nitiduloides]]''\\n* ''[[Saprinus nitidus]]''\\n* ''[[Saprinus nobilis]]''\\n* ''[[Saprinus optabilis]]''\\n* ''[[Saprinus oregonensis]]''\\n* ''[[Saprinus ornatus]]''\\n* ''[[Saprinus pamiricus]]''\\n* ''[[Saprinus pecuinus]]''\\n* ''[[Saprinus pensylvanicus]]''\\n* ''[[Saprinus perinterruptus]]''\\n* ''[[Saprinus pharao]]''\\n* ''[[Saprinus planiusculus]]''\\n* ''[[Saprinus politus]]''\\n* ''[[Saprinus prasinus]]''\\n* ''[[Saprinus profusus]]''\\n* ''[[Saprinus proximus]]''\\n* ''[[Saprinus pseudobicolor]]''\\n* ''[[Saprinus pseudocyaneus]]''\\n* ''[[Saprinus pulcher]]''\\n* ''[[Saprinus punctatissimus]]''\\n* ''[[Saprinus punctulatus]]''\\n* ''[[Saprinus purpuricollis]]''\\n* ''[[Saprinus quadriguttatus]]''\\n* ''[[Saprinus rhodesiae]]''\\n* ''[[Saprinus rhytipterus]]''\\n* ''[[Saprinus ruber]]''\\n* ''[[Saprinus rufulus]]''\\n* ''[[Saprinus rugifer]]''\\n* ''[[Saprinus rugipennis]]''\\n* ''[[Saprinus secchi]]''\\n* ''[[Saprinus sedakovii]]''\\n* ''[[Saprinus semiopacus]]''\\n* ''[[Saprinus semirosus]]''\\n* ''[[Saprinus semistriatus]]''\\n* ''[[Saprinus simplicifrons]]''\\n* ''[[Saprinus simplicipennis]]''\\n* ''[[Saprinus sinaiticus]]''\\n* ''[[Saprinus spernax]]''\\n* ''[[Saprinus sphingis]]''\\n* ''[[Saprinus splendens]]''\\n* ''[[Saprinus steppensis]]''\\n* ''[[Saprinus sternifossa]]''\\n* ''[[Saprinus strigil]]''\\n* ''[[Saprinus stussineri]]''\\n* ''[[Saprinus subcoerulus]]''\\n* ''[[Saprinus subdiptychus]]''\\n* ''[[Saprinus submarginatus]]''\\n* ''[[Saprinus subnitescens]]''\\n* ''[[Saprinus subustus]]''\\n* ''[[Saprinus subvirescens]]''\\n* ''[[Saprinus suturalis]]''\\n* ''[[Saprinus tenuistrius]]''\\n* ''[[Saprinus turcomanicus]]''\\n* ''[[Saprinus walkeri]]''\\n* ''[[Saprinus vatovai]]''\\n* ''[[Saprinus vermiculatus]]''\\n* ''[[Saprinus verschureni]]''\\n* ''[[Saprinus versicolor]]''\\n* ''[[Saprinus virescens]]''\\n* ''[[Saprinus viridanus]]''\\n* ''[[Saprinus viridicatus]]''\\n* ''[[Saprinus viridipennis]]''\\n{{Div col end}}\\n<ref>[http://www.catalogueoflife.org/annual-checklist/2011/search/all/key/saprinus/match/1 Catalogue of Life]</ref><ref>[https://www.biolib.cz/en/taxon/id5066/ Biolib]</ref>\\n\\n==References==\\n{{Reflist}}\\n\\n{{Taxonbar|from=Q4464501}}\\n\\n[[Category:Histeridae]]\\n\\n\\n{{Histeridae-stub}}\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build binarize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique categories in the training dataset\n",
    "all_categories = []\n",
    "\n",
    "for categories in wiki_train.mid_level_categories:\n",
    "    for category in categories:\n",
    "        all_categories.append(category)\n",
    "        \n",
    "unique_categories = list(set(all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the multi-label binarizer on the categories and claims in the training dataset\n",
    "multi_label_binarizer_categories = MultiLabelBinarizer(classes=unique_categories)\n",
    "\n",
    "def binarize_target(result_df):\n",
    "    result_df = result_df.join(pd.DataFrame(multi_label_binarizer_categories.fit_transform(result_df.pop('mid_level_categories')),\n",
    "                          columns=multi_label_binarizer_categories.classes_,\n",
    "                          index=result_df.index))\n",
    "    return result_df\n",
    "\n",
    "wiki_train = binarize_target(wiki_train)\n",
    "wiki_valid = binarize_target(wiki_valid)\n",
    "wiki_test = binarize_target(wiki_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Culture.Arts</th>\n",
       "      <th>STEM.Science</th>\n",
       "      <th>Culture.Performing arts</th>\n",
       "      <th>Geography.Oceania</th>\n",
       "      <th>Culture.Music</th>\n",
       "      <th>Culture.Crafts and hobbies</th>\n",
       "      <th>Culture.Plastic arts</th>\n",
       "      <th>STEM.Chemistry</th>\n",
       "      <th>...</th>\n",
       "      <th>STEM.Medicine</th>\n",
       "      <th>STEM.Technology</th>\n",
       "      <th>Culture.Internet culture</th>\n",
       "      <th>STEM.Information science</th>\n",
       "      <th>Geography.Americas</th>\n",
       "      <th>Culture.Games and toys</th>\n",
       "      <th>Geography.Maps</th>\n",
       "      <th>STEM.Engineering</th>\n",
       "      <th>STEM.Time</th>\n",
       "      <th>Culture.Food and drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>83696</td>\n",
       "      <td>Q25051720</td>\n",
       "      <td>[mutual, combat, term, commonly, used, united,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51073</td>\n",
       "      <td>Q4660583</td>\n",
       "      <td>[way, world, one, nine, nine, four, book, nobe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7594</td>\n",
       "      <td>Q7341497</td>\n",
       "      <td>[robert, ammann, october, one, one, nine, four...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24121</td>\n",
       "      <td>Q3177043</td>\n",
       "      <td>[jennifer, crusie, born, one, nine, four, nine...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35740</td>\n",
       "      <td>Q474397</td>\n",
       "      <td>[tillon, communes, france, commune, ille, vila...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57669</td>\n",
       "      <td>Q6296457</td>\n",
       "      <td>[journey, portugal, viagem, portugal, portugue...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23633</td>\n",
       "      <td>Q5518389</td>\n",
       "      <td>[galena, park, isd, stadium, stadium, situated...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102596</td>\n",
       "      <td>Q63345065</td>\n",
       "      <td>[john, jackson, one, seven, eight, zero, one, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6228</td>\n",
       "      <td>Q1888467</td>\n",
       "      <td>[southfleet, small, village, civil, parishes, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90408</td>\n",
       "      <td>Q25999607</td>\n",
       "      <td>[sanah, moidutty, born, one, july, one, nine, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82547 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              QID                                             tokens  \\\n",
       "83696   Q25051720  [mutual, combat, term, commonly, used, united,...   \n",
       "51073    Q4660583  [way, world, one, nine, nine, four, book, nobe...   \n",
       "7594     Q7341497  [robert, ammann, october, one, one, nine, four...   \n",
       "24121    Q3177043  [jennifer, crusie, born, one, nine, four, nine...   \n",
       "35740     Q474397  [tillon, communes, france, commune, ille, vila...   \n",
       "...           ...                                                ...   \n",
       "57669    Q6296457  [journey, portugal, viagem, portugal, portugue...   \n",
       "23633    Q5518389  [galena, park, isd, stadium, stadium, situated...   \n",
       "102596  Q63345065  [john, jackson, one, seven, eight, zero, one, ...   \n",
       "6228     Q1888467  [southfleet, small, village, civil, parishes, ...   \n",
       "90408   Q25999607  [sanah, moidutty, born, one, july, one, nine, ...   \n",
       "\n",
       "        Culture.Arts  STEM.Science  Culture.Performing arts  \\\n",
       "83696              0             0                        0   \n",
       "51073              0             0                        0   \n",
       "7594               0             0                        0   \n",
       "24121              0             0                        0   \n",
       "35740              0             0                        0   \n",
       "...              ...           ...                      ...   \n",
       "57669              0             0                        0   \n",
       "23633              0             0                        0   \n",
       "102596             0             0                        0   \n",
       "6228               0             0                        0   \n",
       "90408              0             0                        0   \n",
       "\n",
       "        Geography.Oceania  Culture.Music  Culture.Crafts and hobbies  \\\n",
       "83696                   0              0                           0   \n",
       "51073                   0              0                           0   \n",
       "7594                    0              0                           0   \n",
       "24121                   0              0                           0   \n",
       "35740                   0              0                           0   \n",
       "...                   ...            ...                         ...   \n",
       "57669                   0              0                           0   \n",
       "23633                   0              0                           0   \n",
       "102596                  0              0                           0   \n",
       "6228                    0              0                           0   \n",
       "90408                   0              0                           0   \n",
       "\n",
       "        Culture.Plastic arts  STEM.Chemistry  ...  STEM.Medicine  \\\n",
       "83696                      0               0  ...              0   \n",
       "51073                      0               0  ...              0   \n",
       "7594                       0               0  ...              0   \n",
       "24121                      0               0  ...              0   \n",
       "35740                      0               0  ...              0   \n",
       "...                      ...             ...  ...            ...   \n",
       "57669                      0               0  ...              0   \n",
       "23633                      0               0  ...              0   \n",
       "102596                     0               0  ...              0   \n",
       "6228                       0               0  ...              0   \n",
       "90408                      0               0  ...              0   \n",
       "\n",
       "        STEM.Technology  Culture.Internet culture  STEM.Information science  \\\n",
       "83696                 0                         0                         0   \n",
       "51073                 0                         0                         0   \n",
       "7594                  0                         0                         0   \n",
       "24121                 0                         0                         0   \n",
       "35740                 0                         0                         0   \n",
       "...                 ...                       ...                       ...   \n",
       "57669                 0                         0                         0   \n",
       "23633                 0                         0                         0   \n",
       "102596                0                         0                         0   \n",
       "6228                  0                         0                         0   \n",
       "90408                 0                         0                         0   \n",
       "\n",
       "        Geography.Americas  Culture.Games and toys  Geography.Maps  \\\n",
       "83696                    0                       0               0   \n",
       "51073                    1                       0               0   \n",
       "7594                     0                       0               0   \n",
       "24121                    1                       0               0   \n",
       "35740                    0                       0               0   \n",
       "...                    ...                     ...             ...   \n",
       "57669                    0                       0               0   \n",
       "23633                    1                       0               0   \n",
       "102596                   1                       0               0   \n",
       "6228                     0                       0               0   \n",
       "90408                    0                       0               0   \n",
       "\n",
       "        STEM.Engineering  STEM.Time  Culture.Food and drink  \n",
       "83696                  0          0                       0  \n",
       "51073                  0          0                       0  \n",
       "7594                   0          0                       0  \n",
       "24121                  0          0                       0  \n",
       "35740                  0          0                       0  \n",
       "...                  ...        ...                     ...  \n",
       "57669                  0          0                       0  \n",
       "23633                  0          0                       0  \n",
       "102596                 0          0                       0  \n",
       "6228                   0          0                       0  \n",
       "90408                  0          0                       0  \n",
       "\n",
       "[82547 rows x 46 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
